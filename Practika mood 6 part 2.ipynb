{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7882142,"sourceType":"datasetVersion","datasetId":4626328}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/notebook2008c085c5?scriptVersionId=194664325\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-30T08:23:23.326477Z","iopub.execute_input":"2024-08-30T08:23:23.326964Z","iopub.status.idle":"2024-08-30T08:23:23.342929Z","shell.execute_reply.started":"2024-08-30T08:23:23.326916Z","shell.execute_reply":"2024-08-30T08:23:23.341409Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/technology_data.csv\n/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/sports_data.csv\n/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/education_data.csv\n/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/entertainment_data.csv\n/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/business_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-08-30T08:23:23.346119Z","iopub.execute_input":"2024-08-30T08:23:23.347445Z","iopub.status.idle":"2024-08-30T08:23:23.354257Z","shell.execute_reply.started":"2024-08-30T08:23:23.34739Z","shell.execute_reply":"2024-08-30T08:23:23.352767Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-08-30T08:23:23.35598Z","iopub.execute_input":"2024-08-30T08:23:23.356769Z","iopub.status.idle":"2024-08-30T08:23:23.368992Z","shell.execute_reply.started":"2024-08-30T08:23:23.356719Z","shell.execute_reply":"2024-08-30T08:23:23.367166Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/technology_data.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/sports_data.csv\")\ndf3 = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/education_data.csv\")\ndf4 = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/entertainment_data.csv\")\ndf5 = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/business_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-30T08:23:23.371386Z","iopub.execute_input":"2024-08-30T08:23:23.371883Z","iopub.status.idle":"2024-08-30T08:23:23.777664Z","shell.execute_reply.started":"2024-08-30T08:23:23.371823Z","shell.execute_reply":"2024-08-30T08:23:23.776173Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df1, df2, df3, df4, df5], ignore_index=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-30T08:23:23.78133Z","iopub.execute_input":"2024-08-30T08:23:23.78191Z","iopub.status.idle":"2024-08-30T08:23:23.80229Z","shell.execute_reply.started":"2024-08-30T08:23:23.781849Z","shell.execute_reply":"2024-08-30T08:23:23.800741Z"},"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"                                           headlines  \\\n0  Unlocking the science of E Ink displays: Why w...   \n1  Reddit is free education: 9 subreddits that ca...   \n2  Nintendo Switching things up? Leaks suggest la...   \n3  Epic’s Fortnite and new browser engines show c...   \n4  Hubble finds water vapour on small exoplanet i...   \n\n                                         description  \\\n0  That e-reader screen isn't magic - it's E Ink!...   \n1  These subreddits bring the best of the Interne...   \n2  Rumour has it the upcoming Nintendo Switch 2 w...   \n3  The EU's antitrust regulations are forcing App...   \n4  Scientists have used the Hubble Space Telescop...   \n\n                                             content  \\\n0  With their crisp, paper-like screens, e-reader...   \n1  Education is the key to success, it not only l...   \n2  Rumours are heating up that Nintendo may unvei...   \n3  Apple is continuing to open up iOS to comply w...   \n4  Astronomers used the Hubble Space Telescope to...   \n\n                                                 url    category  \n0  https://indianexpress.com/article/technology/t...  technology  \n1  https://indianexpress.com/article/technology/f...  technology  \n2  https://indianexpress.com/article/technology/g...  technology  \n3  https://indianexpress.com/article/technology/t...  technology  \n4  https://indianexpress.com/article/technology/s...  technology  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headlines</th>\n      <th>description</th>\n      <th>content</th>\n      <th>url</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Unlocking the science of E Ink displays: Why w...</td>\n      <td>That e-reader screen isn't magic - it's E Ink!...</td>\n      <td>With their crisp, paper-like screens, e-reader...</td>\n      <td>https://indianexpress.com/article/technology/t...</td>\n      <td>technology</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Reddit is free education: 9 subreddits that ca...</td>\n      <td>These subreddits bring the best of the Interne...</td>\n      <td>Education is the key to success, it not only l...</td>\n      <td>https://indianexpress.com/article/technology/f...</td>\n      <td>technology</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Nintendo Switching things up? Leaks suggest la...</td>\n      <td>Rumour has it the upcoming Nintendo Switch 2 w...</td>\n      <td>Rumours are heating up that Nintendo may unvei...</td>\n      <td>https://indianexpress.com/article/technology/g...</td>\n      <td>technology</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Epic’s Fortnite and new browser engines show c...</td>\n      <td>The EU's antitrust regulations are forcing App...</td>\n      <td>Apple is continuing to open up iOS to comply w...</td>\n      <td>https://indianexpress.com/article/technology/t...</td>\n      <td>technology</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hubble finds water vapour on small exoplanet i...</td>\n      <td>Scientists have used the Hubble Space Telescop...</td>\n      <td>Astronomers used the Hubble Space Telescope to...</td>\n      <td>https://indianexpress.com/article/technology/s...</td>\n      <td>technology</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install --upgrade numpy\n!pip install --upgrade typing-extensions\n!pip install --upgrade filelock\n!pip install --upgrade sympy","metadata":{"execution":{"iopub.status.busy":"2024-08-30T08:23:23.804177Z","iopub.execute_input":"2024-08-30T08:23:23.80475Z","iopub.status.idle":"2024-08-30T08:24:29.954068Z","shell.execute_reply.started":"2024-08-30T08:23:23.804691Z","shell.execute_reply":"2024-08-30T08:24:29.952359Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nCollecting numpy\n  Using cached numpy-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\nUsing cached numpy-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numpy-1.26.4.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: numpy\n  Attempting uninstall: numpy\n\u001b[33m    WARNING: No metadata found in /opt/conda/lib/python3.10/site-packages\u001b[0m\u001b[33m\n\u001b[0m    Found existing installation: numpy 1.26.4\n\u001b[31mERROR: Cannot uninstall numpy 1.26.4, RECORD file not found. You might be able to recover from this via: 'pip install --force-reinstall --no-deps numpy==1.26.4'.\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (4.12.2)\n\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numpy-1.26.4.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (3.15.4)\n\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numpy-1.26.4.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (1.13.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy) (1.3.0)\n\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numpy-1.26.4.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch==1.12.1 torchtext==0.13.1\n","metadata":{"execution":{"iopub.status.busy":"2024-08-30T08:24:29.956287Z","iopub.execute_input":"2024-08-30T08:24:29.956726Z","iopub.status.idle":"2024-08-30T08:24:32.630623Z","shell.execute_reply.started":"2024-08-30T08:24:29.95668Z","shell.execute_reply":"2024-08-30T08:24:32.628685Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"Collecting torch==1.12.1\n  Using cached torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\nCollecting torchtext==0.13.1\n  Using cached torchtext-0.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.9 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.12.1) (4.12.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext==0.13.1) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext==0.13.1) (2.32.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext==0.13.1) (1.26.4)\n\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numpy-1.26.4.dist-info/METADATA'\n\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom sklearn.preprocessing import LabelEncoder\nimport torchtext\n\n\nclass MyDataset(Dataset):\n    def __init__(self, X, y, max_len=100):\n        self.X = X\n        self.y = y\n        self.max_len = max_len\n        \n        self.label_encoder = LabelEncoder().fit(y)\n        self.vocab = torchtext.vocab.GloVe(name='6B', dim=50)\n        self.vocab = torchtext.vocab.Vectors(\"/kaggle/input/glove6b/glove.6B.50d.txt\")\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        label = self.label_encoder.transform([self.y.iloc[idx]])\n        label = torch.tensor(label)\n        \n        text = self.X.iloc[idx]\n        tokens = text.split()\n        \n        if len(tokens) > self.max_len:\n            tokens = tokens[:self.max_len]\n        else:\n            diff = self.max_len - len(tokens)\n            \n            tokens += ['<pad>'] * diff\n        \n        X = self.vocab.get_vecs_by_tokens(tokens, lower_case_backup=True)\n        \n        return X, label[0]\n    \n    \ndataset = MyDataset(df['data'], df['labels'])","metadata":{"execution":{"iopub.status.busy":"2024-08-30T08:24:32.633229Z","iopub.execute_input":"2024-08-30T08:24:32.633843Z","iopub.status.idle":"2024-08-30T08:24:32.813219Z","shell.execute_reply.started":"2024-08-30T08:24:32.633776Z","shell.execute_reply":"2024-08-30T08:24:32.811289Z"},"trusted":true},"execution_count":104,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[104], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyDataset\u001b[39;00m(Dataset):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_torch_home\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m      8\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/_extension.py:64\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_ops.py:1295\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1290\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m-> 1295\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n","File \u001b[0;32m/opt/conda/lib/python3.10/ctypes/__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n","\u001b[0;31mOSError\u001b[0m: /opt/conda/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE"],"ename":"OSError","evalue":"/opt/conda/lib/python3.10/site-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN2at4_ops5zeros4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEE","output_type":"error"}]}]}